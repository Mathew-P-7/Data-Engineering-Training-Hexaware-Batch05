{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ekx_hmRt_QaQ"
      },
      "outputs": [],
      "source": [
        "#  PySpark Session creation\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('EmployeeWorkData').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "data = [\n",
        "Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\",\n",
        "Salary=95000, HoursPerWeek=42),\n",
        "Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\",\n",
        "Salary=87000, HoursPerWeek=45),\n",
        "Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\",\n",
        "Salary=65000, HoursPerWeek=40),\n",
        "Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\",\n",
        "Salary=70000, HoursPerWeek=38),\n",
        "Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\",\n",
        "Salary=99000, HoursPerWeek=48),\n",
        "Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\",\n",
        "Salary=62000, HoursPerWeek=35),\n",
        "Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\",\n",
        "Salary=58000, HoursPerWeek=37),\n",
        "Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000,\n",
        "HoursPerWeek=41),\n",
        "Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\",\n",
        "Salary=91000, HoursPerWeek=46),\n",
        "Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000,\n",
        "HoursPerWeek=36)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data)\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiOunhjq_69F",
        "outputId": "71402477-fc89-45e9-8ad7-8dcdd0b7b859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID|Name |Department |Project        |Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|101  |Ravi |Engineering|AI Engine      |95000 |42          |\n",
            "|102  |Sneha|Engineering|Data Platform  |87000 |45          |\n",
            "|103  |Kabir|Marketing  |Product Launch |65000 |40          |\n",
            "|104  |Anita|Sales      |Client Outreach|70000 |38          |\n",
            "|105  |Divya|Engineering|AI Engine      |99000 |48          |\n",
            "|106  |Amit |Marketing  |Social Media   |62000 |35          |\n",
            "|107  |Priya|HR         |Policy Revamp  |58000 |37          |\n",
            "|108  |Manav|Sales      |Lead Gen       |73000 |41          |\n",
            "|109  |Neha |Engineering|Security Suite |91000 |46          |\n",
            "|110  |Farah|HR         |Onboarding     |60000 |36          |\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Create Views**"
      ],
      "metadata": {
        "id": "y-7C4BjrAgdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Local Temporary View\n",
        "df.createOrReplaceTempView(\"employees_local\")\n",
        "# Global Temporary View\n",
        "df.createOrReplaceGlobalTempView(\"employees_global\")"
      ],
      "metadata": {
        "id": "rmQOxoItAdt1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part A: Exercises on Local View ( employees_local )**\n",
        "\n",
        "1. List all employees working on the \"AI Engine\" project.\n",
        "2. Show all employees from the \"Marketing\" department with salaries greater than\n",
        "60,000.\n",
        "3. Calculate the average salary for each department.\n",
        "4. List the top 3 highest paid employees overall.\n",
        "5. Find employees who work more than 40 hours per week.\n",
        "6. Group by project and display the number of employees per project.\n",
        "7. Drop the local view. Try querying again — what happens?"
      ],
      "metadata": {
        "id": "zsp64VF_A7aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE Project = 'AI Engine'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73BhPG0GBCK5",
        "outputId": "dfba6815-b9c9-46ba-cb19-d39e26e83733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------+------+------------+\n",
            "|EmpID| Name| Department|  Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "|  101| Ravi|Engineering|AI Engine| 95000|          42|\n",
            "|  105|Divya|Engineering|AI Engine| 99000|          48|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE Department = 'Marketing' AND Salary > 60000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0bKOtFzBgY1",
        "outputId": "0fb34d28-b25e-4f4e-bf91-5e32a385ff6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+--------------+------+------------+\n",
            "|EmpID| Name|Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "|  103|Kabir| Marketing|Product Launch| 65000|          40|\n",
            "|  106| Amit| Marketing|  Social Media| 62000|          35|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "spark.sql(\"\"\"\n",
        "SELECT Department, AVG(Salary) AS Average_Salary\n",
        "FROM employees_local\n",
        "GROUP BY Department\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd5cQNcNB1z0",
        "outputId": "50d0fc4c-47e2-4881-face-6b62ac9862bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "| Department|Average_Salary|\n",
            "+-----------+--------------+\n",
            "|      Sales|       71500.0|\n",
            "|Engineering|       93000.0|\n",
            "|  Marketing|       63500.0|\n",
            "|         HR|       59000.0|\n",
            "+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "spark.sql(\"\"\"\n",
        "SELECT * FROM employees_local\n",
        "ORDER BY Salary DESC\n",
        "LIMIT(3)\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90VxIB9SCaND",
        "outputId": "9bac797b-c319-4fd2-9526-3f8ec58c7eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE HoursPerWeek > 40 \").show()"
      ],
      "metadata": {
        "id": "F85LOwdJCzaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042b17c3-8602-4d38-bf5d-5f0599c103a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  108|Manav|      Sales|      Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  6\n",
        "spark.sql(\"\"\"\n",
        "SELECT Project, COUNT(EmpId) AS Employee_Count\n",
        "FROM employees_local\n",
        "GROUP BY Project\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "G_43yWaSDa-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f85263b-d4ac-45ce-b66e-c612eaee6286"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|        Project|Employee_Count|\n",
            "+---------------+--------------+\n",
            "|  Data Platform|             1|\n",
            "|      AI Engine|             2|\n",
            "| Product Launch|             1|\n",
            "|Client Outreach|             1|\n",
            "| Security Suite|             1|\n",
            "|  Policy Revamp|             1|\n",
            "|       Lead Gen|             1|\n",
            "|   Social Media|             1|\n",
            "|     Onboarding|             1|\n",
            "+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  7\n",
        "spark.sql(\"Drop view employees_local\")\n",
        "print(\"Local Temporary View dropped successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsoK2xrDEAdl",
        "outputId": "a18f60ec-2c65-4bd3-b546-78aaac04a0ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local Temporary View dropped successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying again using local temporary view\n",
        "spark.sql(\"SELECT * FROM employees_local\").show()\n",
        "# Error occured and our test is passed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "collapsed": true,
        "id": "g8-04_i_EQ4l",
        "outputId": "eb2a0800-7481-465c-a42e-c9c3dd6ea99c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `employees_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [employees_local], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3778100272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Querying again using local temporary view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM employees_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `employees_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [employees_local], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part B: Exercises on Global View ( employees_global )**\n",
        "1. Retrieve all \"HR\" employees working fewer than 38 hours/week.\n",
        "2. Calculate the total salary payout for each department.\n",
        "3. For each employee, add a derived column Status :\n",
        "If HoursPerWeek > 45 → 'Overworked'\n",
        "Otherwise → 'Normal'\n",
        "4. Count the total number of employees working on each \"Project\" .\n",
        "5. List employees whose salary is above the average salary in their department.\n",
        "6. Open a new Spark session and query \"global_temp.employees_global\" from there."
      ],
      "metadata": {
        "id": "j4fX71PkE0Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   Creating a new session to practice with Global View\n",
        "#  6\n",
        "spark2 = SparkSession.builder.appName('EmployeeWorkData2').getOrCreate()\n",
        "spark2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "zfE-iH8oEzTi",
        "outputId": "6c86adb1-b8e2-4398-d978-6005d4a5a081"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd510697590>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0e51770519cb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EmployeeWorkData</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark2.sql(\"SELECT * FROM global_temp.employees_global\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR083BwUF80q",
        "outputId": "41ca5034-95ee-4a58-d68c-38cdb5b03155"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|\n",
            "|  106| Amit|  Marketing|   Social Media| 62000|          35|\n",
            "|  107|Priya|         HR|  Policy Revamp| 58000|          37|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|\n",
            "|  110|Farah|         HR|     Onboarding| 60000|          36|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "spark2.sql(\"\"\"\n",
        "SELECT * FROM global_temp.employees_global\n",
        "WHERE Department = 'HR' AND HoursPerWeek < 38\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cjgxkJuFLbk",
        "outputId": "9c0ec4fa-2558-4eab-8113-be2fe88a8286"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+-------------+------+------------+\n",
            "|EmpID| Name|Department|      Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "|  107|Priya|        HR|Policy Revamp| 58000|          37|\n",
            "|  110|Farah|        HR|   Onboarding| 60000|          36|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "spark2.sql(\"\"\"\n",
        "SELECT Department, SUM(Salary) AS Total_Salary_Payout\n",
        "FROM global_temp.employees_global\n",
        "GROUP BY Department\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58bSX27IGGj2",
        "outputId": "f2dd5af2-4df6-4b80-b4fe-e040aa6f7983"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------+\n",
            "| Department|Total_Salary_Payout|\n",
            "+-----------+-------------------+\n",
            "|      Sales|             143000|\n",
            "|Engineering|             372000|\n",
            "|  Marketing|             127000|\n",
            "|         HR|             118000|\n",
            "+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "spark2.sql(\"\"\"\n",
        "SELECT *,\n",
        "CASE\n",
        "  WHEN HoursPerWeek > 45 THEN 'Overworked'\n",
        "  ELSE 'Normal'\n",
        "END AS Status\n",
        "FROM global_temp.employees_global\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDpC18EjGdyT",
        "outputId": "4de3fd17-09eb-47af-c392-752b07eede35"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|    Status|\n",
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|    Normal|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|    Normal|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|    Normal|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|    Normal|\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|Overworked|\n",
            "|  106| Amit|  Marketing|   Social Media| 62000|          35|    Normal|\n",
            "|  107|Priya|         HR|  Policy Revamp| 58000|          37|    Normal|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|    Normal|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|Overworked|\n",
            "|  110|Farah|         HR|     Onboarding| 60000|          36|    Normal|\n",
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "spark2.sql(\"\"\"\n",
        "SELECT Project, COUNT(EmpID) AS Employee_Count\n",
        "FROM global_temp.employees_global\n",
        "GROUP BY Project\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnYla9rsHxeH",
        "outputId": "92036c47-4a09-4f7a-9c3b-36ee50e628f2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|        Project|Employee_Count|\n",
            "+---------------+--------------+\n",
            "|  Data Platform|             1|\n",
            "|      AI Engine|             2|\n",
            "| Product Launch|             1|\n",
            "|Client Outreach|             1|\n",
            "| Security Suite|             1|\n",
            "|  Policy Revamp|             1|\n",
            "|       Lead Gen|             1|\n",
            "|   Social Media|             1|\n",
            "|     Onboarding|             1|\n",
            "+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "spark2.sql(\"\"\"\n",
        "SELECT e.*\n",
        "FROM global_temp.employees_global e\n",
        "JOIN (\n",
        "  SELECT Department, AVG(Salary) AS avg_salary\n",
        "  FROM global_temp.employees_global\n",
        "  GROUP BY Department\n",
        ") a\n",
        "ON e.Department = a.Department\n",
        "WHERE e.Salary > a.avg_salary\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18B8TkS8IuXl",
        "outputId": "6e2f58de-a51c-4431-de8d-4d9d586eb7a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  103|Kabir|  Marketing|Product Launch| 65000|          40|\n",
            "|  108|Manav|      Sales|      Lead Gen| 73000|          41|\n",
            "|  110|Farah|         HR|    Onboarding| 60000|          36|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Creating a new spark session for bonus challenges\n",
        "spark3 = SparkSession.builder.appName('EmployeeWorkData3').getOrCreate()\n",
        "spark3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "oUTdp6M9LkUf",
        "outputId": "4a43cfa1-f0c8-436c-f2e7-e2597c2b34e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd510697590>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0e51770519cb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EmployeeWorkData</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Challenges**\n",
        "1. Use a window function to assign rank to employees within each department based\n",
        "on salary.\n",
        "2. Create another view (local or global) that only contains \"Engineering\"\n",
        "employees.\n",
        "3. Create a SQL view that filters out all employees working < 38 hours and saves\n",
        "it as \"active_employees\" ."
      ],
      "metadata": {
        "id": "5ODi5464KwSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "spark3.sql(\"\"\"\n",
        "SELECT EmpID, Name, Department, Salary,\n",
        "RANK() OVER (PARTITION BY Department ORDER BY Salary DESC) AS Salary_Rank\n",
        "FROM global_temp.employees_global\n",
        "ORDER BY Department\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTBRRz4CKaL7",
        "outputId": "217664d6-f71e-493c-b265-32994aceec2b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+------+-----------+\n",
            "|EmpID| Name| Department|Salary|Salary_Rank|\n",
            "+-----+-----+-----------+------+-----------+\n",
            "|  105|Divya|Engineering| 99000|          1|\n",
            "|  101| Ravi|Engineering| 95000|          2|\n",
            "|  109| Neha|Engineering| 91000|          3|\n",
            "|  102|Sneha|Engineering| 87000|          4|\n",
            "|  110|Farah|         HR| 60000|          1|\n",
            "|  107|Priya|         HR| 58000|          2|\n",
            "|  103|Kabir|  Marketing| 65000|          1|\n",
            "|  106| Amit|  Marketing| 62000|          2|\n",
            "|  108|Manav|      Sales| 73000|          1|\n",
            "|  104|Anita|      Sales| 70000|          2|\n",
            "+-----+-----+-----------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "engineering = df.filter(df.Department == \"Engineering\")\n",
        "engineering.createOrReplaceTempView('engineering_employees')"
      ],
      "metadata": {
        "id": "yqXHFukiMogv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "active_employees = df.filter(df.HoursPerWeek >= 38)\n",
        "active_employees.createOrReplaceTempView('active_employees')"
      ],
      "metadata": {
        "id": "0xZIIroeNopb"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}